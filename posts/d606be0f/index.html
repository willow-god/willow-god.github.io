<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>使用BiLSTM神经网络+PyTorch实现汉语分词模型的训练 | LiuShen's Blog</title><meta name="author" content="Willow-God"><meta name="copyright" content="Willow-God"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="使用BiLSTM神经网络+PyTorch实现汉语分词模型的训练本次实验源码及数据集已上传到Github，有需要自行下载。 第一部分：实验分析与设计一、实验内容描述此次实验主要是为了深入比较和评估不同中文分词方法的性能，以便于更全面地理解它们的优点和局限性。在此次实验中我将使用两种主要方法来实现中文分词：一种是基于词典的正向匹配算法，另一种是基于神经网络的双层双向长短时记忆网络（LSTM）模型。 方">
<meta property="og:type" content="article">
<meta property="og:title" content="使用BiLSTM神经网络+PyTorch实现汉语分词模型的训练">
<meta property="og:url" content="https://blog.liushen.fun/posts/d606be0f/index.html">
<meta property="og:site_name" content="LiuShen's Blog">
<meta property="og:description" content="使用BiLSTM神经网络+PyTorch实现汉语分词模型的训练本次实验源码及数据集已上传到Github，有需要自行下载。 第一部分：实验分析与设计一、实验内容描述此次实验主要是为了深入比较和评估不同中文分词方法的性能，以便于更全面地理解它们的优点和局限性。在此次实验中我将使用两种主要方法来实现中文分词：一种是基于词典的正向匹配算法，另一种是基于神经网络的双层双向长短时记忆网络（LSTM）模型。 方">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.qyliu.top/i/2024/03/22/65fc5cc97776f.png">
<meta property="article:published_time" content="2023-10-03T16:00:00.000Z">
<meta property="article:modified_time" content="2023-02-19T16:00:00.000Z">
<meta property="article:author" content="Willow-God">
<meta property="article:tag" content="实验">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="PyTorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.qyliu.top/i/2024/03/22/65fc5cc97776f.png"><link rel="shortcut icon" href="/info/avatar.ico"><link rel="canonical" href="https://blog.liushen.fun/posts/d606be0f/index.html"><link rel="preconnect"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=5.0.0"><link rel="stylesheet" href="/css/custom.css?v=5.0.0"><link rel="stylesheet" href="/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css?v=6.6.0"><link rel="stylesheet" href="/pluginsSrc/@fancyapps/ui/dist/fancybox/fancybox.css?v=5.0.36" media="print" onload="this.media='all'"><script>(()=>{
      const saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
      
      window.btf = {
        saveToLocal: saveToLocal,
        getScript: (url, attr = {}) => new Promise((resolve, reject) => {
          const script = document.createElement('script')
          script.src = url
          script.async = true
          script.onerror = reject
          script.onload = script.onreadystatechange = function() {
            const loadState = this.readyState
            if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
            script.onload = script.onreadystatechange = null
            resolve()
          }

          Object.keys(attr).forEach(key => {
            script.setAttribute(key, attr[key])
          })

          document.head.appendChild(script)
        }),

        getCSS: (url, id = false) => new Promise((resolve, reject) => {
          const link = document.createElement('link')
          link.rel = 'stylesheet'
          link.href = url
          if (id) link.id = id
          link.onerror = reject
          link.onload = link.onreadystatechange = function() {
            const loadState = this.readyState
            if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
            link.onload = link.onreadystatechange = null
            resolve()
          }
          document.head.appendChild(link)
        }),

        addGlobalFn: (key, fn, name = false, parent = window) => {
          const pjaxEnable = true
          if (!pjaxEnable && key.startsWith('pjax')) return

          const globalFn = parent.globalFn || {}
          const keyObj = globalFn[key] || {}
    
          if (name && keyObj[name]) return
    
          name = name || Object.keys(keyObj).length
          keyObj[name] = fn
          globalFn[key] = keyObj
          parent.globalFn = globalFn
        }
      }
    
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode
      
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })()</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"7IX3UBC6JW","apiKey":"4ac2846352e499675081f1277fb961c1","indexName":"My Blog","hitsPerPage":6,"languages":{"input_placeholder":"搜索全站文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"本篇文章从发布到现在已经隔了","messageNext":"天了，里面的内容可能过期了，你要自己甄别一下哟👉👈"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":1000,"languages":{"author":"作者: Willow-God","link":"链接: ","source":"来源: LiuShen's Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: '/pluginsSrc/@egjs/infinitegrid/dist/infinitegrid.min.js?v=4.12.0',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '使用BiLSTM神经网络+PyTorch实现汉语分词模型的训练',
  isPost: true,
  isHome: false,
  isHighlightShrink: undefined,
  isToc: true,
  postUpdate: '2023-02-20 00:00:00'
}</script><link rel="stylesheet" href="/config/Yozai-Medium/result.css"><link rel="stylesheet" href="/config/memos/memos.css"></head><body><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><!-- hexo injector head_end start --><link rel="stylesheet" href="/config/swiper/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="/config/swiper/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="LiuShen's Blog" type="application/atom+xml">
<link rel="alternate" href="/rss2.xml" title="LiuShen's Blog" type="application/rss+xml">
<div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="wizard-scene"><div class="wizard-objects"><div class="wizard-square"></div><div class="wizard-circle"></div><div class="wizard-triangle"></div></div><div class="wizard"><div class="wizard-body"></div><div class="wizard-right-arm"><div class="wizard-right-hand"></div></div><div class="wizard-left-arm"><div class="wizard-left-hand"></div></div><div class="wizard-head"><div class="wizard-beard"></div><div class="wizard-face"><div class="wizard-adds"></div></div><div class="wizard-hat"><div class="wizard-hat-of-the-hat"></div><div class="wizard-four-point-star --first"></div><div class="wizard-four-point-star --second"></div><div class="wizard-four-point-star --third"></div></div></div></div></div></div><script async="async">(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }
  
  preloader.initLoading()
  
  let loaded = false;
  
  window.addEventListener('load', () => { 
      if (!loaded) {
          preloader.endLoading();
          loaded = true;
      }
  });

  setTimeout(() => {
      if (!loaded) {
          preloader.endLoading();
          loaded = true;
      }
  }, 5000);

  
  window.addEventListener('load',() => { preloader.endLoading() })
  setTimeout(function(){preloader.endLoading();}, 3000);
  document.getElementById('loading-box').addEventListener('click',()=> {preloader.endLoading()})

  if (true) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><!--.avatar-img.is-center--><!--  img(src=url_for(theme.avatar.img) onerror=`onerror=null;src='${theme.error_img.flink}'` alt="avatar")--><div class="is-center" id="sidebar-avatar"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/03/21/65fc570ca9fe7.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">Willow-God</div><div class="author-info__description">清羽 〄 飞扬</div></div><div class="site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">52</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">69</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/willow-god"><i class="fab fa-github"></i><span>Follow Me 🛫</span></a><div class="menu-info-social-icons is-center"><a class="social-icon" href="mailto:01@liushen.fun" target="_blank" title="Email"><i class="fa-solid fa-envelope"></i></a><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=2411457922&amp;site=qq&amp;menu=yes" target="_blank" title="QQ：2411457922"><i class="fa-brands fa-qq"></i></a><a class="social-icon" href="https://wakatime.com/@LiuShen" target="_blank" title="Wakatime"><i class="fa-solid fa-chart-column"></i></a><a class="social-icon" href="https://blog.liushen.fun/atom.xml" target="_blank" title="rss地址"><i class="fa-solid fa-rss"></i></a></div><div class="menus_items visible"><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fas fa-home"></i><span> 导航</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/"><i class="fa-fw fa-solid fa-house-laptop"></i><span> 博客主页</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.liushen.fun/"><i class="fa-fw fa-solid fa-house-flag"></i><span> 导航主页</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://xc.liushen.fun/"><i class="fa-fw fa fa-camera-retro"></i><span> 个人相册</span></a></li></ul></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fa fa-graduation-cap"></i><span> 整理</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时光卷轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 文章标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 文章分类</span></a></li><li><a class="site-page child" href="/charts/"><i class="fa-fw fa-solid fa-chart-pie"></i><span> 文章通览</span></a></li></ul></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fa-solid fa-user-group"></i><span> 友人</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链展示</span></a></li><li><a class="site-page child" href="/addlink/"><i class="fa-fw fa fa-at"></i><span> 友链申请</span></a></li><li><a class="site-page child" href="/fcircle/"><i class="fa-fw fa-solid fa-circle-nodes"></i><span> 朋友动态</span></a></li></ul></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fa fa-paper-plane"></i><span> 留言</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/comment/"><i class="fa-fw fa-solid fa-chalkboard"></i><span> 留言白板</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://m.liushen.fun/"><i class="fa-fw fa-solid fa-basketball"></i><span> 盐焗星球</span></a></li></ul></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fa-solid fa-stethoscope"></i><span> 服务</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://um.liushen.fun/"><i class="fa-fw fa-solid fa-eye-low-vision"></i><span> 访客统计</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://pan.liushen.fun/"><i class="fa-fw fa-solid fa-laptop-file"></i><span> 资源分享</span></a></li><li><a class="site-page child" href="/subscribe/"><i class="fa-fw fa-solid fa-rss"></i><span> 订阅本站</span></a></li></ul></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fa fa-list"></i><span> 关于</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-address-card"></i><span> 站长资料</span></a></li><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-commenting"></i><span> 日常说说</span></a></li><li><a class="site-page child" href="/devices/"><i class="fa-fw fa-solid fa-tachograph-digital"></i><span> 我的设备</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(https://cdn.qyliu.top/i/2024/03/22/65fc5cc97776f.png);"><nav id="nav"><span id="blog-info"><a href="/" title="LiuShen's Blog"><span class="site-name">LiuShen's Blog</span></a></span><div id="menus"></div><div class="menus_items visible"><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fas fa-home"></i><span> 导航</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/"><i class="fa-fw fa-solid fa-house-laptop"></i><span> 博客主页</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.liushen.fun/"><i class="fa-fw fa-solid fa-house-flag"></i><span> 导航主页</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://xc.liushen.fun/"><i class="fa-fw fa fa-camera-retro"></i><span> 个人相册</span></a></li></ul></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fa fa-graduation-cap"></i><span> 整理</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时光卷轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 文章标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 文章分类</span></a></li><li><a class="site-page child" href="/charts/"><i class="fa-fw fa-solid fa-chart-pie"></i><span> 文章通览</span></a></li></ul></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fa-solid fa-user-group"></i><span> 友人</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链展示</span></a></li><li><a class="site-page child" href="/addlink/"><i class="fa-fw fa fa-at"></i><span> 友链申请</span></a></li><li><a class="site-page child" href="/fcircle/"><i class="fa-fw fa-solid fa-circle-nodes"></i><span> 朋友动态</span></a></li></ul></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fa fa-paper-plane"></i><span> 留言</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/comment/"><i class="fa-fw fa-solid fa-chalkboard"></i><span> 留言白板</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://m.liushen.fun/"><i class="fa-fw fa-solid fa-basketball"></i><span> 盐焗星球</span></a></li></ul></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fa-solid fa-stethoscope"></i><span> 服务</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://um.liushen.fun/"><i class="fa-fw fa-solid fa-eye-low-vision"></i><span> 访客统计</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://pan.liushen.fun/"><i class="fa-fw fa-solid fa-laptop-file"></i><span> 资源分享</span></a></li><li><a class="site-page child" href="/subscribe/"><i class="fa-fw fa-solid fa-rss"></i><span> 订阅本站</span></a></li></ul></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fa fa-list"></i><span> 关于</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-address-card"></i><span> 站长资料</span></a></li><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-commenting"></i><span> 日常说说</span></a></li><li><a class="site-page child" href="/devices/"><i class="fa-fw fa-solid fa-tachograph-digital"></i><span> 我的设备</span></a></li></ul></div></div><center id="name-container"><a id="page-name" href="javascript:btf.scrollToDest(0, 500)">PAGE_NAME</a></center><div id="nav-right"><div id="travellings"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html" title="友链接力-随机开往"><i class="fa-solid fa-bus fa-fw"></i></a></div><div id="ten-years"><a class="site-page" target="_blank" rel="noopener" href="https://foreverblog.cn/go.html" title="友链接力-十年之约"><i class="fa-brands fa-nfc-symbol fa-fw"></i></a></div><div id="random"><a class="site-page" href="javascript:randomPost()" title="随机前往一个文章"><i class="fa-solid fa-shuffle fa-fw"></i></a></div><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i></span></div><div id="toggle-menu"><span class="site-page" href="javascript:void(0);" title="展开菜单"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">使用BiLSTM神经网络+PyTorch实现汉语分词模型的训练</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-03T16:00:00.000Z" title="发表于 2023-10-04 00:00:00">2023-10-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-02-19T16:00:00.000Z" title="更新于 2023-02-20 00:00:00">2023-02-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/">学习资料</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>21分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="使用BiLSTM神经网络+PyTorch实现汉语分词模型的训练"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/posts/d606be0f/#post-comment"><span id="twikoo-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="使用BiLSTM神经网络-PyTorch实现汉语分词模型的训练"><a href="#使用BiLSTM神经网络-PyTorch实现汉语分词模型的训练" class="headerlink" title="使用BiLSTM神经网络+PyTorch实现汉语分词模型的训练"></a>使用BiLSTM神经网络+PyTorch实现汉语分词模型的训练</h1><p><strong>本次实验源码及数据集已上传到<a target="_blank" rel="external nofollow noopener noreferrer" href="/go.html?u=aHR0cHM6Ly9naXRodWIuY29tL3dpbGxvdy1nb2QvQmlMU1RNLVNwbGl0V29yZHM=">Github</a>，有需要自行下载。</strong></p>
<h2 id="第一部分：实验分析与设计"><a href="#第一部分：实验分析与设计" class="headerlink" title="第一部分：实验分析与设计"></a>第一部分：实验分析与设计</h2><h3 id="一、实验内容描述"><a href="#一、实验内容描述" class="headerlink" title="一、实验内容描述"></a>一、实验内容描述</h3><p>此次实验主要是为了深入比较和评估不同中文分词方法的性能，以便于更全面地理解它们的优点和局限性。在此次实验中我将使用两种主要方法来实现中文分词：一种是基于词典的正向匹配算法，另一种是基于神经网络的双层双向长短时记忆网络（LSTM）模型。</p>
<p><strong>方法一：基于词典的正向匹配算法</strong></p>
<p>这种方法比较简单，在这种方法中，我们将利用一个包含大部分常用中文词汇的词典。然后，使用正向匹配算法，将待分词的文本与词典中的词汇逐一匹配。匹配成功的部分将被输出作为分词结果。这种方法的优势在于其简单性和速度，但它可能无法处理未知词汇或歧义情况。相较于神经网络非常容易实现，也不需要麻烦的数据预处理，还不需要修改数据格式，主要算法就是字符串匹配。</p>
<p><strong>方法二：基于神经网络的双层双向LSTM模型</strong></p>
<p>在这个方法中，我们将使用pyTorch构建一个神经网络来实现中文词语分词算法。首先，我们将准备一个中规模的中文语料文件，作为训练数据集。我们将使用PyTorch框架构建一个双层双向LSTM模型，该模型能够学习如何分词。在训练过程中，模型将学习词汇和上下文之间的关系，以便更准确地分词。 </p>
<p><strong>数据集</strong></p>
<p>为了评估两种方法的性能，我们将使用以下数据集：</p>
<p><strong>语料文件</strong>：一个包含大量中文文本的语料文件，用于神经网络的训练。该语料文件将包括各种文本类型和难度级别的文本。其中使用空格分开每一个词语，如下其中一句所示：</p>
<figure class="highlight txt"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1. 迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附  图片  １  张  ）</span><br></pre></td></tr></tbody></table></figure>

<p><strong>测试数据</strong>：一个用于评估两种分词方法的测试数据集，包括中文文本。这些测试数据将用于比较方法的性能。其中数据为一句句话，但是没有使用空格进行分割。</p>
<p><strong>测试数据结果</strong>：测试数据对应的结果，每一行都和 测试数据相对应，不过每个词语之间有空格间隔。测试数据和测试数据结果如下：</p>
<figure class="highlight txt"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 测试数据：共同创造美好的新世纪——二○○一年新年贺词</span><br><span class="line">2. 测试数据结果：共同  创造  美好  的  新  世纪  ——  二○○一年  新年  贺词</span><br></pre></td></tr></tbody></table></figure>

<p><strong>数据预处理</strong>：准备词典、对语料文件进行分词和标记化，以及创建神经网络模型的输入数据。</p>
<p><strong>模型训练</strong>：使用语料文件进行神经网络模型的训练。模型将学习如何分词。</p>
<p><strong>模型评估</strong>：使用测试数据集来评估两种分词方法的性能，包括准确率、召回率、F1分数等指标。</p>
<p><strong>结果分析</strong>：比较基于词典的正向匹配算法和基于神经网络的方法的性能，讨论它们的优势和不足之处。</p>
<p><strong>实验验证</strong>：重复实验，以确保结果的稳定性和一致性。</p>
<p>通过这个实验，我们希望得出关于不同中文分词方法的性能比较，并为选择最适合特定任务的分词方法提供有力依据。</p>
<h3 id="二、实验内容与设计思想"><a href="#二、实验内容与设计思想" class="headerlink" title="二、实验内容与设计思想"></a>二、实验内容与设计思想</h3><p><strong>在第一种方法中</strong>，首先，我们使用简单的正向匹配算法，对于字符串中的每个字符串进行匹配。从文本的开头开始，每次匹配最长的词语，直到文本被分完为止。如果当前位置没有匹配到任何词语，则将当前位置的字符作为一个单独的词语。</p>
<p>具体来说，该算法的实现过程如下：</p>
<ol>
<li><p>初始化一个空的词语列表tokens，以及文本的长度text_len和词典中最长词语的长度max_word_len。</p>
</li>
<li><p>从文本的开头开始，依次匹配最长的词语。具体地，从max_word_len开始，依次尝试匹配长度为max_word_len、max_word_len-1、…、1的词语，直到匹配到一个词语为止。</p>
</li>
<li><p>如果匹配到了一个词语，则将该词语添加到tokens列表中，并将当前位置i移动到词语的末尾。</p>
</li>
<li><p>如果没有匹配到任何词语，则将当前位置的字符作为一个单独的词语，并将当前位置i移动到下一个位置。</p>
</li>
<li><p>重复步骤2到步骤4，直到文本被分完为止。</p>
</li>
</ol>
<p>该算法的时间复杂度为O(n^2)，其中n为文本的长度。在实际应用中，该算法的效率较低，但是实现简单，可以作为其他分词算法的基础。</p>
<p><strong>第二种方法主要需要使用pytorch</strong>，所以比较麻烦，首先我们需要对于所有句子进行预处理，由于模型无法直接输入文字，所以我们得将其进行编码，编码这里我选择的是每个字出现的频率，按照从小到大排序进行编码，这样一方面可以实现我们的编码功能，另一方面还有一部分字频特征，比较直接。通过这种方式将其转换为数字列表后，再将结果进行处理，通过上网查阅资料可知，在这种模型我们的结果需要使用编码进行标识是否是一个词语或者单独的字。编码规则如下：</p>
<figure class="highlight txt"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. target_dict = {'B': 0, # begin</span><br><span class="line">2.                  'M': 1, # middle</span><br><span class="line">3.                  'E': 2, # end</span><br><span class="line">4.                  'S': 3, # single</span><br><span class="line">5.                  'N': 4} # null</span><br></pre></td></tr></tbody></table></figure>

<p>编码成功后，我们的每个句子转换为了数字类型，除此之外，如果有需要我们还需要将其转换为one-Hot编码，不过在torch模型中不是很需要，所以这里我们就不转换了。</p>
<p>数据预处理后，我们就需要创建模型了，为了模型更加贴合我们的实验，我选择了双层双向LSTM。双向LSTM（Bidirectional LSTM）是一种常用的循环神经网络模型，它可以同时考虑输入序列的前向和后向信息，从而更好地捕捉序列中的上下文信息。在分词模型中，双向LSTM可以很好地处理中文分词中的歧义问题，提高分词的准确性。</p>
<p>具体来说，双向LSTM可以将输入序列分别从前向后和从后向前进行处理，得到两个输出序列。这两个输出序列可以分别表示输入序列中当前位置之前和之后的上下文信息。然后，这两个输出序列可以被合并起来，得到一个综合的上下文表示，用于进行下一步的分类或预测。</p>
<p>在分词模型中，双向LSTM可以很好地处理中文分词中的歧义问题。例如，在中文分词中，一个汉字可能既可以作为一个词语的开始，也可以作为另一个词语的中间部分。这种歧义问题可以通过双向LSTM来解决，因为双向LSTM可以同时考虑当前位置之前和之后的上下文信息，从而更好地判断当前位置的标记。</p>
<p>然后，我选择了交叉熵作为损失函数，并且定义了优化器，然后将数据上传到GPU上进行运算，现在整个项目就比较清晰了。</p>
<h3 id="三、实验使用环境"><a href="#三、实验使用环境" class="headerlink" title="三、实验使用环境"></a>三、实验使用环境</h3><p>系统：Windows 11专业版 22H2 22621.2361<br>软件：Visual Studio Code<br>环境：Anaconda3(base):Python 3.9.13<br>      PyTorch 2.0.1+cu118<br>硬件：LEGION R9000P 2021H<br>      CPU:R7-5800H<br>      GPU:RTX 3060 Laptop</p>
<h2 id="第二部分：实验调试与结果分析"><a href="#第二部分：实验调试与结果分析" class="headerlink" title="第二部分：实验调试与结果分析"></a>第二部分：实验调试与结果分析</h2><h3 id="一、调试过程"><a href="#一、调试过程" class="headerlink" title="一、调试过程"></a>一、调试过程</h3><p><strong>首先我们实现第一种正向最大匹配分词实现汉字分词</strong>，我们的词典中有若干词汇，并且按照首字母顺序进行排序，如下图所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/03/22/65fc5cea7e33f.png" alt="dirctory.txt"></p>
<p>我们所需要实现的功能就是，遍历一串句子的每一个字，使用这个字及后面的若干字组成临时词汇，在列表中搜索对应的词汇，如果有这个词汇，分词，并进行下一句话的分词，如果没有，单独成词，并继续遍历下一个词汇。实现代码如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义正向最大匹配分词函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_max_match</span>(<span class="params">text</span>):</span><br><span class="line">    tokens = []</span><br><span class="line">    text_len = <span class="built_in">len</span>(text)</span><br><span class="line">    max_word_len = <span class="built_in">max</span>(<span class="built_in">len</span>(word) <span class="keyword">for</span> word <span class="keyword">in</span> dictionary_data)</span><br><span class="line"></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; text_len:</span><br><span class="line">        matched = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(max_word_len, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> i + j &lt;= text_len:</span><br><span class="line">                word = text[i:i + j]</span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">in</span> dictionary_data:</span><br><span class="line">                    tokens.append(word)</span><br><span class="line">                    i += j</span><br><span class="line">                    matched = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> matched:</span><br><span class="line">            tokens.append(text[i])</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokens</span><br></pre></td></tr></tbody></table></figure>

<p>其中的directory_data就是我们的字典文件，经过split函数，将其每个空格隔开的每个单词分别放入到列表中便于查询。 我们测试一条句子，得到以下结果：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/03/22/65fc5cf94fc8e.png" alt="正向匹配结果"></p>
<p>我们可以看见，这个准确率还不错，除了“—”和“二○○一年”没有出现在字典中，其他的分的效果挺好的。然后计算一下准确率，F1值，召回率参数，这一步是个比较难的点，由于是文字的原因，我们无法很好的对比他是否分割完毕或者在这里分割。为了统一标准，我们选择了，对比词汇是否正确划分出来，并且使用正确划分的词汇数量进行评判。我们写了如下代码循环进行测试：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 准确率,召回率, F1值</span></span><br><span class="line">自己分的词语总数 = <span class="number">0</span></span><br><span class="line">正确结果的词语总数 = <span class="number">0</span></span><br><span class="line">正确的词语总数 = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">data = test_data[:<span class="number">100</span>]</span><br><span class="line"><span class="comment"># print('data[:10]:', list(data)[:5])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 循环处理每行文本</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取测试数据和测试结果</span></span><br><span class="line">    test_data_line = data[i]</span><br><span class="line">    result_data_line = test_result[i]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用正向最大匹配算法分词</span></span><br><span class="line">    segmented_text = forward_max_match(test_data_line)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算匹配的分词数量</span></span><br><span class="line">    自己分的词语总数 += <span class="built_in">len</span>(segmented_text)</span><br><span class="line">    正确结果的词语总数 += <span class="built_in">len</span>(result_data_line)</span><br><span class="line"></span><br><span class="line">    j = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算正确的分词数量</span></span><br><span class="line">    <span class="keyword">for</span> seg_word <span class="keyword">in</span> segmented_text:</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> seg_word <span class="keyword">in</span> result_data_line:</span><br><span class="line">            <span class="comment"># 如果分词结果在正确结果中,则，查找所有匹配的位置并append到locations中</span></span><br><span class="line">            locations = find_same_word_locations(result_data_line, seg_word)</span><br><span class="line">            <span class="comment"># 遍历locations中的每个位置，如果分词结果在正确结果中，则正确的词语总数加1</span></span><br><span class="line">            <span class="keyword">for</span> loc <span class="keyword">in</span> locations:</span><br><span class="line">                <span class="comment"># 计算对比两个在字符串中的位置是否相同</span></span><br><span class="line">                <span class="keyword">if</span> get_word_location(segmented_text, j) == get_word_location(result_data_line, loc):</span><br><span class="line">                    <span class="comment"># 如果相同，直接加1</span></span><br><span class="line">                    正确的词语总数 += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 查看分词计算进度</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"分词计算进度：<span class="subst">{i + <span class="number">1</span>}</span>/<span class="subst">{<span class="built_in">len</span>(data)}</span>\t准确率：<span class="subst">{正确的词语总数 / 自己分的词语总数}</span>\t"</span>, end=<span class="string">'\r'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">准确率 = 正确的词语总数 / 自己分的词语总数</span><br><span class="line">召回率 = 正确的词语总数 / 正确结果的词语总数</span><br><span class="line">F1值 = <span class="number">2</span> * 准确率 * 召回率 / (准确率 + 召回率)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"\n正确分词数量：<span class="subst">{正确的词语总数}</span>"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"总分词数量：<span class="subst">{自己分的词语总数}</span>"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"正确结果的词语总数：<span class="subst">{正确结果的词语总数}</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"准确率：<span class="subst">{准确率:<span class="number">.2</span>%}</span>"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"召回率：<span class="subst">{召回率:<span class="number">.2</span>%}</span>"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"F1值：<span class="subst">{F1值:<span class="number">.2</span>%}</span>"</span>)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p>最终我们得到相关数据：</p>
<ul>
<li><p>正确分词数量：4983</p>
</li>
<li><p>总分词数量：5655</p>
</li>
<li><p>正确结果的词语总数：5414</p>
</li>
<li><p>准确率：88.12%</p>
</li>
<li><p>召回率：92.04%</p>
</li>
<li><p>F1值：90.04%</p>
</li>
</ul>
<p><strong>第二种方法我们选择使用PyTorch实现神经网络进行分词</strong>，我们首先定义一下思路我们想要实现功能，那么必须要向神经网络中传输数据，我们的数据应该是什么形状的呢？由于是句子，首先句子的长度可能会有较大变化，其次是维度，我们每个句子一行行堆砌为列表，最终的结果应该也会很大。数量多没问题，但是如果数据变长度，我们能很好地是西安功能吗？首先我写了一个BP神经网络简单实现，发现最终效果很差，所以，为了模型更好的拟合，我选择最大长度为32，大于32的句子删掉，小于32的句子末尾补零，当然我们按照所有的标点符号进行划分，确保大部分数据都能派上用场。理论可行，实践开始：</p>
<p>获取训练数据：我们的语料文件是每个词语之间用空格分隔开，但是我们输入数据中不应该有这些空格，这些空格应该是以标签的形式输入，所以我们首先需要将空格去掉，然后按照标点符号进行断句，经过统计，无标点符号的句子长度几乎所有都不会超过32，这样就不会浪费数据了。处理代码如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_train_data</span>(<span class="params">file_path</span>):   <span class="comment">#file_path = 'data/train.txt'</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path,<span class="string">'r'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.read()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将读取到的文本按照标点符号和换行符进行切分，得到一个列表</span></span><br><span class="line">    lines = re.split(<span class="string">r"[，。！？、（）—《》…；“”\n]"</span>,lines)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 去掉列表中的空字符串及空格</span></span><br><span class="line">    lines = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> lines <span class="keyword">if</span> line.strip()]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 去掉每个句子中的空格</span></span><br><span class="line">    lines = [line.replace(<span class="string">" "</span>,<span class="string">""</span>) <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 去掉所有长度大于max_len的句子</span></span><br><span class="line">    lines = [line <span class="keyword">for</span> line <span class="keyword">in</span> lines <span class="keyword">if</span> <span class="built_in">len</span>(line)&lt;=max_len]</span><br><span class="line"></span><br><span class="line">    phrase_expel = lines</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"phrase_expel:"</span>,phrase_expel[:<span class="number">10</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"phrase_expel len:"</span>,<span class="built_in">len</span>(phrase_expel))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'data/generate_pkl/train_data.pkl'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f: <span class="comment">#把这个处理后的文件当作训练数据</span></span><br><span class="line">        pkl.dump(phrase_expel, f)   <span class="comment">#把文件写成pkl格式</span></span><br></pre></td></tr></tbody></table></figure>

<p>其中处理句子长度并在末尾添加零的代码写到后面，因为后面还会使用到这个数据。</p>
<p>下面就是我们的标签数据了，我们需要想办法将其中不同的分词保存成一种数据，经过上网查询，我选择了使用对应字母来表示每个字的位置，通过转换，我们获取到其中几条数据的输出：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/03/22/65fc5d08ea9c8.png" alt="训练数据分句结果"></p>
<p>模型无法识别汉字，所以我们需要给汉字编码，这里我选择使用字频字典进行编码。统计字频后保存字频文件以便于后面测试时调用，另外我们需要空缺出0的编码，以进行后续32个字符的补齐。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_vocab_dict</span>(<span class="params">file_path</span>):  <span class="comment">#'data/train_data.pkl'</span></span><br><span class="line">    vocab_dic = {}</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        z = pkl.load(f)</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> z:</span><br><span class="line">            <span class="keyword">for</span> hang <span class="keyword">in</span> line:  <span class="comment">#统计词频，按照词多到少排列</span></span><br><span class="line">                vocab_dic[hang] = vocab_dic.get(hang, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">        vocab_dic_sorted = <span class="built_in">sorted</span>(vocab_dic.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 按照词频排序后，构建词典，词频越高，索引越小，并且下标从1开始</span></span><br><span class="line">    vocab_dic2 = {}</span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> <span class="built_in">enumerate</span>(vocab_dic_sorted):</span><br><span class="line">        vocab_dic2[j[<span class="number">0</span>]] = i + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 展示前10个词</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"vocab_dic2:"</span>,<span class="built_in">list</span>(vocab_dic2.items())[:<span class="number">10</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"vocab_dic2 len:"</span>,<span class="built_in">len</span>(vocab_dic2))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'data/generate_pkl/vocab.pkl'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pkl.dump(vocab_dic2, f)</span><br></pre></td></tr></tbody></table></figure>

<p>下面我们只需要给训练数据，也就是那一串串字符搞成数字，再在末尾补0，即可达到要求。</p>
<p>下面我们开始定义模型类和相关参数，考虑到是一个分词模型，我们选择双向LSTM实现，为了效果达到最好，我尝试选择一个双层双向LSTM进行训练。模型定义如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BiLSTM_Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embedding_size, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(BiLSTM_Model, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.embedding = nn.Embedding(vocab_size, embedding_size)</span><br><span class="line">        <span class="variable language_">self</span>.bilstm1 = nn.LSTM(embedding_size, hidden_size, bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dropout1 = nn.Dropout(<span class="number">0.6</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bilstm2 = nn.LSTM(hidden_size * <span class="number">2</span>, hidden_size, bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dropout2 = nn.Dropout(<span class="number">0.6</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(hidden_size * <span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.embedding(x)</span><br><span class="line">        x, _ = <span class="variable language_">self</span>.bilstm1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.dropout1(x)</span><br><span class="line">        x, _ = <span class="variable language_">self</span>.bilstm2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.dropout2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></tbody></table></figure>

<p>这个模型中，我们可以看到，我们添加了两个双向LSTM，并在其中穿插Dropout层防止过拟合，并且在最终添加了一个fc全连接层，将最终结果转化为分类结果。然后我们只需要定义模型并训练，即可得到我们的结果。</p>
<p>注意训练时我们需要选择GPU进行计算，先定义模型和模型所使用的损失函数优化器，然后将模型和数据送到GPU即可：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = BiLSTM_Model(voc_size + <span class="number">1</span>, config.embed_dim, config.hidden_dim)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)</span><br></pre></td></tr></tbody></table></figure>

<p>通过这部分运行代码的结果我们可以看见我们的模型大致内容。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/03/22/65fc5d16a741e.png" alt="模型参数"></p>
<p>然后将数据上传到GPU上，注意在上传时我们应该选择自己的设备，如果设备不支持GPU，就可以直接进行下一步了，如果支持进行这一步骤并选择设备id以提高速度。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将数据和模型上传到GPU进行计算</span></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"><span class="built_in">print</span>(device)</span><br><span class="line">model.to(device)</span><br><span class="line">train_data_list = [i.to(device) <span class="keyword">for</span> i <span class="keyword">in</span> train_data_list]</span><br><span class="line">target_list = [i.to(device) <span class="keyword">for</span> i <span class="keyword">in</span> target_list]</span><br></pre></td></tr></tbody></table></figure>

<p>下面我们就可以进行训练过程了。训练过程我们每个epoch分开进行训练，训练结束后输出损失再进行下一步</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config.epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"Epoch:"</span>, epoch + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="built_in">len</span>(train_data_list))):</span><br><span class="line">        model.zero_grad()</span><br><span class="line">        input_data = train_data_list[i].view(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        target = target_list[i].view(-<span class="number">1</span>)</span><br><span class="line">        output = model(input_data)</span><br><span class="line">        loss = loss_function(output.view(-<span class="number">1</span>, <span class="number">5</span>), target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"Loss:"</span>, loss.item())</span><br><span class="line">    <span class="comment"># # 打印这个epoch的准确率</span></span><br><span class="line">    <span class="comment"># with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#     right_num = 0</span></span><br><span class="line">    <span class="comment">#     all_num = 0</span></span><br><span class="line">    <span class="comment">#     for i in tqdm(range(len(train_data_list))):</span></span><br><span class="line">    <span class="comment">#         input_data = train_data_list[i].view(1, -1)</span></span><br><span class="line">    <span class="comment">#         target = target_list[i].view(-1)</span></span><br><span class="line">    <span class="comment">#         output = model(input_data)</span></span><br><span class="line">    <span class="comment">#         output = torch.argmax(output.view(-1, 5), dim=1)</span></span><br><span class="line">    <span class="comment">#         for j in range(len(output)):</span></span><br><span class="line">    <span class="comment">#             if output[j] == target[j]:</span></span><br><span class="line">    <span class="comment">#                 right_num += 1</span></span><br><span class="line">    <span class="comment">#             all_num += 1</span></span><br><span class="line">    <span class="comment">#     print("Accuracy:", right_num / all_num)</span></span><br></pre></td></tr></tbody></table></figure>

<p>这里我们可以看见很多的系数，如config.Learning_rate，config.epoch等等，这里我们是定义了一个参数类以保存各种参数，如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Config</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment"># 参数设置类，包含一些相关参数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.vocab = pkl.load(<span class="built_in">open</span>(<span class="string">'data/generate_pkl/vocab.pkl'</span>, <span class="string">'rb'</span>))  <span class="comment"># 读取词表</span></span><br><span class="line">        <span class="variable language_">self</span>.train_data = pkl.load(<span class="built_in">open</span>(<span class="string">'data/generate_pkl/train_data.pkl'</span>, <span class="string">'rb'</span>))  <span class="comment"># 读取训练数据</span></span><br><span class="line">        <span class="variable language_">self</span>.target = pkl.load(<span class="built_in">open</span>(<span class="string">'data/generate_pkl/target.pkl'</span>, <span class="string">'rb'</span>))  <span class="comment"># 读取标签</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.learning_rate = <span class="number">0.0015</span>  <span class="comment"># 学习率</span></span><br><span class="line">        <span class="variable language_">self</span>.epoch = <span class="number">4</span>  <span class="comment"># epoch次数</span></span><br><span class="line">        <span class="variable language_">self</span>.dropout = <span class="number">0.6</span> <span class="comment"># dropout</span></span><br><span class="line">        <span class="variable language_">self</span>.max_len = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.output_size = <span class="number">4</span></span><br><span class="line">        <span class="variable language_">self</span>.embed_dim = <span class="number">128</span></span><br><span class="line">        <span class="variable language_">self</span>.hidden_dim = <span class="number">64</span></span><br><span class="line">        <span class="variable language_">self</span>.hout1 = <span class="number">32</span></span><br><span class="line">        <span class="variable language_">self</span>.hout2 = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.num_layers = <span class="number">2</span> <span class="comment"># 测试双层LSTM神经网络</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"---------创建参数类完成---------"</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# 词表大小："</span>, <span class="built_in">len</span>(<span class="variable language_">self</span>.vocab))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# 训练数据大小："</span>, <span class="built_in">len</span>(<span class="variable language_">self</span>.train_data))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# 标签大小："</span>, <span class="built_in">len</span>(<span class="variable language_">self</span>.target))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# 输出大小："</span>, <span class="variable language_">self</span>.output_size)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# 嵌入层大小："</span>, <span class="variable language_">self</span>.embed_dim)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# 隐藏层大小："</span>, <span class="variable language_">self</span>.hidden_dim)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# 第一层输出大小："</span>, <span class="variable language_">self</span>.hout1)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# 第二层输出大小："</span>, <span class="variable language_">self</span>.hout2)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# 学习率："</span>, <span class="variable language_">self</span>.learning_rate)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# epoch次数："</span>, <span class="variable language_">self</span>.epoch)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# dropout层："</span>, <span class="variable language_">self</span>.dropout)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"# 每个LSTM中循环次数："</span>, <span class="variable language_">self</span>.num_layers)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"-------------------------------"</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>最终输出结果如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/03/22/65fc5d2bd6848.png" alt="训练结果"></p>
<p>现在开始系统的测定我们的准确率，这里的召回率，我选择使用字母的对应进行测试，比如这个字符在原标签中是一个E，如果变成了其他字符，则表示错误，反之正确。当然我们的测试数据需要通过原来保存的字典转换成数据。</p>
<p>下面进行测试：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将测试数据和测试结果转换为tensor</span></span><br><span class="line">test_data_tensor = torch.tensor(test_data_id)</span><br><span class="line">test_result_tensor = torch.tensor(test_result_id)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(test_data_tensor.shape)</span><br><span class="line"><span class="built_in">print</span>(test_result_tensor.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入模型进行预测</span></span><br><span class="line">output = model(test_data_tensor)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将预测结果转换为numpy数组</span></span><br><span class="line">output = output.detach().numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将预测结果转换为标签</span></span><br><span class="line">output = np.argmax(output, axis=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># print(output[0])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将预测结果转换为字母</span></span><br><span class="line">output = [[<span class="built_in">list</span>(target_dict.keys())[<span class="built_in">list</span>(target_dict.values()).index(word)] <span class="keyword">for</span> word <span class="keyword">in</span> line] <span class="keyword">for</span> line <span class="keyword">in</span> output]</span><br><span class="line"><span class="comment"># print(output[0])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理output</span></span><br><span class="line">output = [<span class="string">''</span>.join(line) <span class="keyword">for</span> line <span class="keyword">in</span> output]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去除output和test_result中的"N"</span></span><br><span class="line">output = [line.replace(<span class="string">"N"</span>, <span class="string">""</span>) <span class="keyword">for</span> line <span class="keyword">in</span> output]</span><br><span class="line">test_result = [line.replace(<span class="string">"N"</span>, <span class="string">""</span>) <span class="keyword">for</span> line <span class="keyword">in</span> test_result]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历二者中的每一行的每一个字母，计算预测结果和真实结果的准确率</span></span><br><span class="line">acc = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(output)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(output[i])):</span><br><span class="line">        <span class="keyword">if</span> output[i][j] == test_result[i][j]:</span><br><span class="line">            acc += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"准确率："</span>, acc/<span class="built_in">sum</span>([<span class="built_in">len</span>(line) <span class="keyword">for</span> line <span class="keyword">in</span> test_result]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"召回率："</span>, acc/<span class="built_in">sum</span>([<span class="built_in">len</span>(line) <span class="keyword">for</span> line <span class="keyword">in</span> output]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"F1值："</span>, <span class="number">2</span>*acc/(<span class="built_in">sum</span>([<span class="built_in">len</span>(line) <span class="keyword">for</span> line <span class="keyword">in</span> test_result])+<span class="built_in">sum</span>([<span class="built_in">len</span>(line) <span class="keyword">for</span> line <span class="keyword">in</span> output])))</span><br></pre></td></tr></tbody></table></figure>

<p>经过测试数据的转换，处理，最终得到结果：准确率：88.04%</p>
<p>本次实验完毕</p>
<h3 id="二、实验结果及分析"><a href="#二、实验结果及分析" class="headerlink" title="二、实验结果及分析"></a>二、实验结果及分析</h3><h4 id="1、结果描述"><a href="#1、结果描述" class="headerlink" title="1、结果描述"></a>1、结果描述</h4><p>在本次实验中，我们比较了基于词典的正向匹配分词方法和基于神经网络的双层双向LSTM分词方法的性能。以下是实验结果的描述：</p>
<p>基于词典的正向匹配方法：</p>
<p>该方法在测试数据上表现出较高的准确率，88.12%。大多数常见词汇能够被正确分词。</p>
<p>但在处理未知词汇和复杂的歧义情况时，其性能下降明显，甚至直接无法进行划分。</p>
<p>基于神经网络的双层双向LSTM方法：</p>
<p>该方法在测试数据上表现出更好的适应性，能够更好地处理未知词汇和歧义情况。</p>
<p>虽然在测试数据中两者准确率类似，但是在不在词典或语料中的词汇中，准确率相对较高，尤其在复杂文本类型中，其性能明显优于基于词典的方法。</p>
<h4 id="2、实验现象分析"><a href="#2、实验现象分析" class="headerlink" title="2、实验现象分析"></a>2、实验现象分析</h4><p>在分析实验结果时，我们观察到以下现象：</p>
<p>基于词典的正向匹配方法在处理常见词汇上表现良好，但在面对未知词汇和歧义情况时遇到挑战。</p>
<p>基于神经网络的双层双向LSTM方法能够更好地理解上下文信息，从而更好地处理未知词汇和复杂语境。</p>
<h4 id="3、影响因素讨论"><a href="#3、影响因素讨论" class="headerlink" title="3、影响因素讨论"></a>3、影响因素讨论</h4><p>实验结果受以下因素的影响：</p>
<p>训练数据：基于神经网络的方法受训练数据的质量和多样性影响。更大规模、多样性的语料库有助于提高模型的性能。</p>
<p>模型架构：选择双层双向LSTM模型是为了考虑上下文信息，但其他架构可能在不同任务上表现更好。</p>
<p>测试数据：测试数据的多样性和难度对两种方法的性能评估至关重要。</p>
<h4 id="4、综合分析和结论"><a href="#4、综合分析和结论" class="headerlink" title="4、综合分析和结论"></a>4、综合分析和结论</h4><p>综合分析实验结果，我们得出以下结论：</p>
<p>基于神经网络的双层双向LSTM分词方法在处理中文分词任务时具有更高的适应性，特别是在面对未知词汇和复杂上下文的情况下。</p>
<p>基于词典的正向匹配方法适合处理简单的文本和常见词汇，但在处理复杂文本时表现不佳。</p>
<p>因此，选择合适的分词方法应该取决于应用场景和任务要求。如果需要更好的泛化性能和适应性，基于神经网络的方法可能是更好的选择。然而，基于词典的方法仍然具有在一些特定情况下表现良好的优点。</p>
<h3 id="三、实现小结、建议及体会"><a href="#三、实现小结、建议及体会" class="headerlink" title="三、实现小结、建议及体会"></a>三、实现小结、建议及体会</h3><p>在此次实验中，我使用了两种不同的中文分词方法，一种基于词典的正向匹配，另一种基于神经网络的双层双向LSTM模型。这体现了自然语言处理领域的多样性，不同方法适用于不同的应用场景。</p>
<p>在实验中，我们测试了两种方法在各种方面的差异，基于神经网络的方法在面对未知词汇和复杂上下文时表现更好，但是训练时间较长。而基于词典的方法适用于处理常见词汇和简单文本，并且不需要进行训练即可直接运行。这突出了每种方法的优势和局限性。</p>
<p>为了保证实验的准确性，我重复进行了几次实验，最终得到了相对稳定的结果，并且进行对比，体现了实验的严谨性。</p>
<p>实验还启发了我思考如何进一步改进中文分词方法。可以尝试不同的神经网络架构、更大规模的数据集、迁移学习等方法来提高分词性能。</p>
<p>这个实验不仅让我更深入地了解了中文分词方法的工作原理，还强调了数据的重要性以及不同方法在不同情境下的适用性。这将有助于我更明智地选择和应用中文分词方法，以满足特定任务的需求。</p>
<p><strong>实验中所有源码均以上传Github，链接在最上方，需要者自行下载。</strong></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.liushen.fun/">Willow-God</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.liushen.fun/posts/d606be0f/">https://blog.liushen.fun/posts/d606be0f/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.liushen.fun" target="_blank">LiuShen's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AE%9E%E9%AA%8C/">实验</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch</a></div><div class="post-share"><div class="social-share" data-image="https://cdn.qyliu.top/i/2024/03/22/65fc5cc97776f.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="/pluginsSrc/butterfly-extsrc/sharejs/dist/css/share.min.css?v=1.1.3" media="print" onload="this.media='all'"><script src="/pluginsSrc/butterfly-extsrc/sharejs/dist/js/social-share.min.js?v=1.1.3" defer=""></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>来😍鼠标过来一点~</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/config/img/wechat.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/config/img/wechat.png" alt="微信"></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/config/img/wechat.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/config/img/wechat.png" alt="支付宝"></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="prev-post pull-left" href="/posts/b9e434f6/" title="怎么解决jupyter的烦人命令行黑框框"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/03/25/6600de3108d17.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">怎么解决jupyter的烦人命令行黑框框</div></div></a><a class="next-post pull-right" href="/posts/f7016786/" title="Java课程主要内容回顾"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://wallpapercave.com/wp/wp7250277.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Java课程主要内容回顾</div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a href="/posts/3ecd60/" title="Java实现多端图书管理系统"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://wallpapercave.com/wp/wp7250277.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-05</div><div class="title">Java实现多端图书管理系统</div></div></a></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/03/21/65fc570ca9fe7.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info-name">Willow-God</div><div class="author-info-description">清羽 〄 飞扬</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">52</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">69</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/willow-god"><i class="fab fa-github"></i><span>Follow Me 🛫</span></a><div class="card-info-social-icons"><a class="social-icon" href="mailto:01@liushen.fun" target="_blank" title="Email"><i class="fa-solid fa-envelope"></i></a><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=2411457922&amp;site=qq&amp;menu=yes" target="_blank" title="QQ：2411457922"><i class="fa-brands fa-qq"></i></a><a class="social-icon" href="https://wakatime.com/@LiuShen" target="_blank" title="Wakatime"><i class="fa-solid fa-chart-column"></i></a><a class="social-icon" href="https://blog.liushen.fun/atom.xml" target="_blank" title="rss地址"><i class="fa-solid fa-rss"></i></a></div></div><div class="card-widget" id="card-poem"><div id="poem_sentence"></div><div id="poem_info"><div id="poem_dynasty"></div><div id="poem_author"></div></div></div><script src="/js/jinrishici.js" charset="utf-8"></script><script type="text/javascript">jinrishici.load(function(result) {
var sentence = document.querySelector("#poem_sentence")
var author = document.querySelector("#poem_author")
var dynasty = document.querySelector("#poem_dynasty")

var sentenceText = result.data.content
sentenceText = sentenceText.substr(0, sentenceText.length - 1);
sentence.innerHTML = sentenceText
dynasty.innerHTML = result.data.origin.dynasty
author.innerHTML = result.data.origin.author + '《' + result.data.origin.title + '》'
});</script><div class="card-widget card-announcement"><div class="item-headline"><i class="fa fa-user"></i><span>欢迎来访者</span></div><div id="welcome-info"></div><script src="/js/txmap.js"></script><script data-pjax="data-pjax">var longitude="108.546767";
var Latitude="34.579480";
var txkey="44BBZ-IZPLZ-V6PXP-ZYLRT-JKFH3-DOFJ6";
var ipLoacation;
window.onload = () => {welcometxmap()};
document.addEventListener("pjax:complete", welcometxmap());</script></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><p><strong>博客架构概览：</strong><br>⚙️框架核心：Hexo<br>🕹️界面设计：Butterfly<br>🔮安全保障：长亭雷池<br>🔩管理工具：宝塔面板，1Panel<br>🎰服务器支持：阿里云，腾讯云<br>🎲CDN加速：多吉云，无畏云<br><strong>快捷跳转地址：</strong><br>👻博客主站：<a href="https://blog.liushen.fun">blog.liushen.fun</a><br>😶‍🌫️博客分栏：<a target="_blank" rel="noopener" href="https://www.qingyang.eu.org">qingyang.eu.org</a><br>🤖个人导航：<a target="_blank" rel="noopener" href="https://www.liushen.fun">www.liushen.fun</a><br></p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/config/img/notice.gif" alt="可爱捏" title="可爱捏" style="width:100%; border-radius:10px;"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8BiLSTM%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-PyTorch%E5%AE%9E%E7%8E%B0%E6%B1%89%E8%AF%AD%E5%88%86%E8%AF%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83"><span class="toc-text">使用BiLSTM神经网络+PyTorch实现汉语分词模型的训练</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%EF%BC%9A%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90%E4%B8%8E%E8%AE%BE%E8%AE%A1"><span class="toc-text">第一部分：实验分析与设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9%E6%8F%8F%E8%BF%B0"><span class="toc-text">一、实验内容描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9%E4%B8%8E%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="toc-text">二、实验内容与设计思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E9%AA%8C%E4%BD%BF%E7%94%A8%E7%8E%AF%E5%A2%83"><span class="toc-text">三、实验使用环境</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%EF%BC%9A%E5%AE%9E%E9%AA%8C%E8%B0%83%E8%AF%95%E4%B8%8E%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90"><span class="toc-text">第二部分：实验调试与结果分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%B0%83%E8%AF%95%E8%BF%87%E7%A8%8B"><span class="toc-text">一、调试过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E5%8F%8A%E5%88%86%E6%9E%90"><span class="toc-text">二、实验结果及分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E3%80%81%E7%BB%93%E6%9E%9C%E6%8F%8F%E8%BF%B0"><span class="toc-text">1、结果描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E3%80%81%E5%AE%9E%E9%AA%8C%E7%8E%B0%E8%B1%A1%E5%88%86%E6%9E%90"><span class="toc-text">2、实验现象分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%E3%80%81%E5%BD%B1%E5%93%8D%E5%9B%A0%E7%B4%A0%E8%AE%A8%E8%AE%BA"><span class="toc-text">3、影响因素讨论</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%E3%80%81%E7%BB%BC%E5%90%88%E5%88%86%E6%9E%90%E5%92%8C%E7%BB%93%E8%AE%BA"><span class="toc-text">4、综合分析和结论</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E7%8E%B0%E5%B0%8F%E7%BB%93%E3%80%81%E5%BB%BA%E8%AE%AE%E5%8F%8A%E4%BD%93%E4%BC%9A"><span class="toc-text">三、实现小结、建议及体会</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/4dc716ec/" title="Friend-Circle-Lite:轻量友链朋友圈"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/07/19/6699436fe02ec.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Friend-Circle-Lite:轻量友链朋友圈"></a><div class="content"><a class="title" href="/posts/4dc716ec/" title="Friend-Circle-Lite:轻量友链朋友圈">Friend-Circle-Lite:轻量友链朋友圈</a><time datetime="2024-08-11T16:02:00.000Z" title="更新于 2024-08-12 00:02:00">2024-08-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/a64defb4/" title="魔改笔记七：分类条及外链卡片"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/08/10/66b74df1ab511.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="魔改笔记七：分类条及外链卡片"></a><div class="content"><a class="title" href="/posts/a64defb4/" title="魔改笔记七：分类条及外链卡片">魔改笔记七：分类条及外链卡片</a><time datetime="2024-08-09T17:40:00.000Z" title="更新于 2024-08-10 01:40:00">2024-08-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/159f1aa5/" title="域名迁移至 blog.liushen.fun"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/08/10/66b6479e1d33c.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="域名迁移至 blog.liushen.fun"></a><div class="content"><a class="title" href="/posts/159f1aa5/" title="域名迁移至 blog.liushen.fun">域名迁移至 blog.liushen.fun</a><time datetime="2024-08-09T08:00:00.000Z" title="更新于 2024-08-09 16:00:00">2024-08-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/3850e950/" title="CloudFlare实用项目推荐"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/07/31/66a922cb9adcc.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CloudFlare实用项目推荐"></a><div class="content"><a class="title" href="/posts/3850e950/" title="CloudFlare实用项目推荐">CloudFlare实用项目推荐</a><time datetime="2024-07-31T17:32:00.000Z" title="更新于 2024-08-01 01:32:00">2024-08-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap" style="background: transparent"><div id="footer_icons"><div><a class="icon_link" rel="noopener external nofollow" href="https://www.qyliu.top/" title="导航站点" target="_blank"><i class="fa-solid fa-compass"></i></a><a class="icon_link" rel="noopener external nofollow" href="https://admin.qidian.qq.com/static_proxy/b2b-qq/wpa-link/index.html#/person?uin=2411457922" title="联系QQ" target="_blank"><i class="fa-brands fa-qq"></i></a><a class="icon_link" rel="noopener external nofollow" href="https://github.com/willow-god" title="我的github主页" target="_blank"><i class="fa-brands fa-github"></i></a><a class="icon_link" rel="noopener external nofollow" href="mailto:01@liushen.fun" title="发送邮件至博主邮箱" target="_blank"><i class="fa-solid fa-envelope"></i></a></div><img class="footer_logo" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/05/12/663f9fc48820a.png" onclick="btf.scrollToDest(0,500)" title="返回顶部"><div><a class="icon_link" rel="noopener external nofollow" href="https://wakatime.com/@LiuShen" title="Wikitime" target="_blank"><i class="fa-solid fa-clock"></i></a><a class="icon_link" rel="noopener external nofollow" href="https://gitlab.com/" title="gitlab" target="_blank"><i class="fa-brands fa-gitlab"></i></a><a class="icon_link" href="/shuoshuo/" title="日常说说" data-pjax-state="data-pjax-state"><i class="fa-solid fa-file-pen"></i></a><a class="icon_link" href="/comment/" title="留言板" data-pjax-state="data-pjax-state"><i class="fa-solid fa-comment"></i></a></div></div><div id="footer_content"><div class="footer-group"><h3 class="footer-title">关于本站</h3><div class="footer-links"><a class="footer-item" target="_blank" href="https://www.qyliu.top/">导航站点</a><a class="footer-item" href="/shuoshuo/">日常说说</a><a class="footer-item" target="_blank" href="https://um.liushen.fun/share/G8C2aR0IszHE5VBl/blog.liushen.fun">访客信息</a><a class="footer-item" target="_blank" href="https://m.liushen.fun/">盐焗星球</a><a class="footer-item" target="_blank" href="https://listen.qyliu.top/">在线状态</a><a class="footer-item" href="/subscribe/">订阅本站</a></div></div><div class="footer-group"><h3 class="footer-title">加入组织</h3><div class="footer-links"><a class="footer-item" target="_blank" href="https://www.boyouquan.com/home">博友圈</a><a class="footer-item" target="_blank" href="https://boke.lu/">博客录</a><a class="footer-item" target="_blank" href="https://blogwe.com/">博客我们</a><a class="footer-item" target="_blank" href="https://firewood.news/">积薪站点</a><a class="footer-item" target="_blank" href="https://bf.zzxworld.com/">发现博客</a><a class="footer-item" target="_blank" href="https://ourblo.gs/">OurBlogs</a></div></div><div class="footer-group"><h3 class="footer-title">文章整理</h3><div class="footer-links"><a class="footer-item" href="/categories/博客管理/">博客管理</a><a class="footer-item" href="/categories/学习资料/">学习资料</a><a class="footer-item" href="/categories/日常分享/">日常分享</a><a class="footer-item" href="/achieve/">时光卷轴</a><a class="footer-item" href="/charts/">文章通览</a><a class="footer-item" href="/categories/">查看全部</a></div></div><div class="footer-group"><h3 class="footer-title">文章标签</h3><div class="footer-links"><a class="footer-item" href="/tags/JavaScript/">JS知识</a><a class="footer-item" href="/tags/Hexo/">本站框架</a><a class="footer-item" href="/tags/机器学习/">机器学习</a><a class="footer-item" href="/tags/日记/">个人日记</a><a class="footer-item" href="/tags/CSS/">CSS知识</a><a class="footer-item" href="/tags/">查看全部</a></div></div><div class="footer-group"><h3 class="footer-title">自建工具</h3><div class="footer-links"><a class="footer-item" target="_blank" rel="noopener" href="https://docs_s.tianli0.top/">必应AI</a><a class="footer-item" target="_blank" rel="noopener" href="https://chat.qyliu.top/">NextGPT</a><a class="footer-item" target="_blank" rel="noopener" href="https://draw.qyliu.top/">随心画板</a><a class="footer-item" target="_blank" rel="noopener" href="https://mindmap.qyliu.top/">思维导图</a><a class="footer-item" target="_blank" rel="noopener" href="https://ittools.qyliu.top/">IT工具箱</a><a class="footer-item" target="_blank" rel="noopener" href="https://calcium.qyliu.top/">在线计算</a></div></div><div class="footer-group" id="friend-links-in-footer"><h3 class="footer-title">友链<button title="换一批" href="javascript:;" onclick="liushen.randomLink()"><i class="fa-solid fa-rotate-right"></i></button></h3><div class="footer-links"><a class="footer-item" target="_blank" href="https://blog.liushen.fun">测试1</a><a class="footer-item" target="_blank" href="https://blog.liushen.fun">测试2</a><a class="footer-item" target="_blank" href="https://blog.liushen.fun">测试3</a><a class="footer-item" target="_blank" href="https://blog.liushen.fun">测试4</a><a class="footer-item" target="_blank" href="https://blog.liushen.fun">测试5</a><a class="footer-item" href="/link/" data-pjax-state="data-pjax-state">查看更多</a></div></div></div><div id="footer-bottom"><div class="footer-bottom-content"><div class="footer-bottom-left"><span class="copyright">©2021 - 2024 By <a target="_blank" rel="noopener" href="https://blog.liushen.fun/about/" title="点击访问&quot;LiuShen&quot;的主页" style="margin-left:5px">LiuShen</a></span><div><a class="footer-bottom-link" target="_blank" href="https://beian.miit.gov.cn/" rel="noopener external nofollow" title="工信部备案号">陕ICP备2024028531号</a><a class="footer-bottom-link" target="_blank" href="https://beian.mps.gov.cn/#/query/webSearch?code=61011602000637" rel="noopener external nofollow" title="公安备案号">陕公网安备61011602000637号</a></div></div><div class="footer-bottom-right"> <div id="runtime" title="本站运行时间">本站已苟活：0 天 0 时 0 分 0 秒</div><div> <a class="footer-bottom-link" target="_blank" href="https://www.dogecloud.com/" rel="noopener external nofollow" title="本站通过多吉云CDN提供站点加速">多吉云CDN</a><a class="footer-bottom-link" target="_blank" href="https://hexo.io/zh-cn/" rel="noopener external nofollow" title="本站使用Hexo架构搭建而成">Hexo静态框架</a><a class="footer-bottom-link" target="_blank" href="https://butterfly.js.org/" rel="noopener external nofollow" title="本站由Butterfly主题魔改而成">Butterfly主题</a></div></div></div></div></div><script>if (!window.liushen) {
  window.liushen = {
    saveData: (key, data) => {
      localStorage.setItem(key, JSON.stringify({
        time: Date.now(),
        data: data
      }));
    },

    loadData: (key, validTimeInMinutes) => {
      let storedData = JSON.parse(localStorage.getItem(key));
      if (storedData) {
        let elapsedTime = Date.now() - storedData.time;
        if (elapsedTime >= 0 && elapsedTime < validTimeInMinutes * 60000) {
          return storedData.data;
        }
      }
      return null;
    },

    runtime: () => {
      const formatTime = (unit) => unit > 9 ? unit : "0" + unit;
      const startTime = new Date('2021/12/12 01:27:36').getTime();
      const currentTime = Date.now();
      let elapsedTimeInSeconds = Math.round((currentTime - startTime) / 1000);

      let runtimeText = "本站已苟活：";
      if (elapsedTimeInSeconds >= 86400) {
        runtimeText += `${formatTime(Math.floor(elapsedTimeInSeconds / 86400))} 天 `;
        elapsedTimeInSeconds %= 86400;
      }
      if (elapsedTimeInSeconds >= 3600) {
        runtimeText += `${formatTime(Math.floor(elapsedTimeInSeconds / 3600))} 时 `;
        elapsedTimeInSeconds %= 3600;
      }
      if (elapsedTimeInSeconds >= 60) {
        runtimeText += `${formatTime(Math.floor(elapsedTimeInSeconds / 60))} 分 `;
        elapsedTimeInSeconds %= 60;
      }
      runtimeText += `${formatTime(elapsedTimeInSeconds)} 秒`;

      const runtimeElement = document.getElementById("runtime");
      if (runtimeElement) {
        runtimeElement.innerHTML = runtimeText;
      }
      setTimeout(window.liushen.runtime, 1000);
    },

    randomLink: () => {
      let linksData = window.liushen.loadData("links", 30);
      if (linksData) {
        let linkElements = document.querySelectorAll("#friend-links-in-footer .footer-item");
        if (!linkElements.length) return;

        for (let i = 0; i < linkElements.length; i++) {
          let randomIndex = Math.floor(Math.random() * linksData.length);
          linkElements[i].innerText = linksData[randomIndex].name;
          linkElements[i].href = linksData[randomIndex].link;
          linksData.splice(randomIndex, 1);
        }
      } else {
        fetch("/flink_count.json")
          .then(response => response.json())
          .then(data => {
            window.liushen.saveData("links", data.link_list);
            window.liushen.randomLink();
          });
      }
    }
  };
}

if (true) {
  window.liushen.randomLink();
  document.addEventListener("DOMContentLoaded", window.liushen.randomLink);
  window.liushen.runtime();
} else {
  window.liushen.randomLink();
  window.liushen.runtime();
}</script></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="cat" onclick="toggleLive2dVisibility()" title="小猫显隐"><i class="fa-solid fa-cat"></i></button><button id="fullscreen" onclick="toggleFullScreen()" title="全屏切换"><i class="fa-solid fa-expand"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="fa-solid fa-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="fa-solid fa-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="fa-solid fa-arrow-rotate-right"></i></div><div class="rightMenu-item" id="menu-home"><i class="fa-solid fa-house"></i></div></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" id="copy" href="javascript:rm.copySelect();"><i class="fa-solid fa-copy"></i><span>复制选中文字</span></a><a class="rightMenu-item" id="reply" href="javascript:rm.replySelect();"><i class="fa-regular fa-comment"></i><span>评论选中段落</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" href="/archives/"><i class="fa-solid fa-archive"></i><span>文章时间线</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="fa-solid fa-folder-open"></i><span>文章分大类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="fa-solid fa-tags"></i><span>文章小标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuNormal"><a class="rightMenu-item menu-link" id="menu-radompage" href="/comment/"><i class="fa-solid fa-shoe-prints"></i><span>随心留言板</span></a><div class="rightMenu-item" id="menu-translate"><i class="fa-solid fa-earth-asia"></i><span>繁简模式切换</span></div><div class="rightMenu-item" id="menu-darkmode"><i class="fa-solid fa-moon"></i><span>切换亮暗模式</span></div><div class="rightMenu-item" id="menu-live2dvisibility"><i class="fa-solid fa-cat"></i><span>小猫显示隐藏</span></div><div class="rightMenu-item" id="menu-print"><i class="fa-solid fa-print fa-fw"></i><span>打印整个页面</span></div><a class="rightMenu-item menu-link" id="statement" href="/statement/"><i class="fa-regular fa-copyright fa-fw"></i><span>网站声明</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js?v=5.0.0"></script><script src="/js/main.js?v=5.0.0"></script><script src="/js/jquery-3.7.1.slim.min.js?v=5.0.0"></script><script src="/js/others.js?v=5.0.0"></script><script src="/js/echarts.min.js?v=5.0.0"></script><script src="/js/rightmenu.js?v=5.0.0"></script><script src="/js/tw_cn.js?v=5.0.0"></script><script src="/pluginsSrc/@fancyapps/ui/dist/fancybox/fancybox.umd.js?v=5.0.36"></script><script src="/pluginsSrc/instant.page/instantpage.js?v=5.2.0" type="module"></script><script src="/pluginsSrc/vanilla-lazyload/dist/lazyload.iife.min.js?v=19.1.3"></script><div class="js-pjax"><script>(() => {
  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.qyliu.top',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.qyliu.top',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))

    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else btf.getScript('/pluginsSrc/twikoo/dist/twikoo.all.min.js?v=1.6.38').then(init)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[aside.card_aside.card_aside.card_newest_comments.code]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo.qyliu.top',
        region: '',
        pageSize: 5,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        btf.saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      btf.getScript('/pluginsSrc/twikoo/dist/twikoo.all.min.js?v=1.6.38').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = btf.saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  btf.addGlobalFn('pjaxComplete', newestCommentInit, 'twikoo_newestComment')
})</script><script src="/config/memos/memos.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="/pluginsSrc/butterfly-extsrc/dist/fireworks.min.js?v=1.1.3"></script><script src="/pluginsSrc/pjax/pjax.min.js?v=0.2.8"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

const triggerPjaxFn = (val) => {
  if (!val) return
  Object.values(val).forEach(fn => { fn() })
}

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjaxSendOnce')
  btf.removeGlobalFnEvent('themeChange')

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  triggerPjaxFn(window.globalFn.pjaxSend)
})

document.addEventListener('pjax:complete', () => {
  btf.removeGlobalFnEvent('pjaxCompleteOnce')
  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  triggerPjaxFn(window.globalFn.pjaxComplete)
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div><script src="/pluginsSrc/algoliasearch/dist/algoliasearch-lite.umd.js?v=4.24.0"></script><script src="/pluginsSrc/instantsearch.js/dist/instantsearch.production.min.js?v=4.73.3"></script><script src="/js/search/algolia.js?v=5.0.0"></script></div></div><!-- hexo injector body_end start --><script data-pjax="">
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/a64defb4/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/08/10/66b74df1ab511.webp" alt="" onerror="this.src=/img/error-page.png; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-08-10</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/a64defb4/&quot;);" href="javascript:void(0);" alt="">魔改笔记七：分类条及外链卡片</a><div class="blog-slider__text">虽然说域名换了几乎等于从头开始，但是仍然浇不灭我对于网站的热情，该进行的还是得进行。很久都没有总结魔改了，这篇文章就将最近魔改最大的几个部分进行记录，同时对有需要的朋友提供帮助。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/a64defb4/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/159f1aa5/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/08/10/66b6479e1d33c.webp" alt="" onerror="this.src=/img/error-page.png; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-08-09</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/159f1aa5/&quot;);" href="javascript:void(0);" alt="">域名迁移至 blog.liushen.fun</a><div class="blog-slider__text">近期遇见了一个很烦人的事情，bing的所有搜索结果全部消失，我也不知道是怎么回事，已经在联系bing管理员了，不过，其实我很早之前就像换域名了，今天趁此机会，干脆直接换了得了！原有的域名301至新域名，不会影响任何使用。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/159f1aa5/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/3850e950/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/07/31/66a922cb9adcc.webp" alt="" onerror="this.src=/img/error-page.png; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-08-01</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/3850e950/&quot;);" href="javascript:void(0);" alt="">CloudFlare实用项目推荐</a><div class="blog-slider__text">之前我向大家推荐过vercel上的一些项目，都非常的有趣实用，最近，在和朋友安小歪的聊天中，发现了一些很好玩的cloud flare项目，比如临时邮箱，临时文件传送，计数统计，等等，很多项目都非常好玩，于是在此推荐给大家。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/3850e950/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/4dc716ec/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/07/19/6699436fe02ec.webp" alt="" onerror="this.src=/img/error-page.png; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-07-21</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/4dc716ec/&quot;);" href="javascript:void(0);" alt="">Friend-Circle-Lite:轻量友链朋友圈</a><div class="blog-slider__text">前两天出现了友链朋友圈因为版本原因导致无法运行的问题，虽然我已经改好了，但是由于bundle文件过大，经常导致加载较慢，于是我自己手搓了一个轻量化友链朋友圈，同时支持通过提交issue实现邮箱订阅本站最新文章，也算是友链朋友圈部署新思路啦，适合喜欢轻量和免费快速的朋友尝试！</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/4dc716ec/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/67189760/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.qyliu.top/i/2024/07/06/6688d4b63b50f.webp" alt="" onerror="this.src=/img/error-page.png; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-07-06</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/67189760/&quot;);" href="javascript:void(0);" alt="">Spikformer脉冲神经网络学习</a><div class="blog-slider__text">近期我们进行了人工智能实训，我们小组选择的是脉冲神经网络，不同于原先的神经网络，这个网络采用的是脉冲信号，目前脉冲神经网络的效果并不是很好，但是因为是一个全新的神经网络架构，并且基于生物启发的计算方式，使得它们在处理稀疏和非结构化数据时具有独特的优势。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/67189760/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer="" src="/config/swiper/swiper.min.js"></script><script defer="" data-pjax="" src="/config/swiper/swiper_init.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"superSample":2,"width":250,"height":500,"position":"left","hOffset":0,"vOffset":-140},"mobile":{"show":false,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>